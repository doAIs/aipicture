"""
å·¥å…·å‡½æ•° - è¾…åŠ©åŠŸèƒ½
"""
import os
from datetime import datetime
from PIL import Image
import torch
import numpy as np
from typing import List, Tuple, Optional
from config.modules_config import OUTPUT_IMAGES_DIR


def save_image(image: Image.Image, filename: str = None, subfolder: str = None) -> str:
    """
    ä¿å­˜å›¾ç‰‡åˆ°è¾“å‡ºç›®å½•
    
    Args:
        image: PIL Imageå¯¹è±¡
        filename: æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
        subfolder: å­æ–‡ä»¶å¤¹åç§°
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """

    
    # åˆ›å»ºå­æ–‡ä»¶å¤¹
    if subfolder:
        save_dir = os.path.join(OUTPUT_IMAGES_DIR, subfolder)
        os.makedirs(save_dir, exist_ok=True)
    else:
        save_dir = OUTPUT_IMAGES_DIR
        os.makedirs(save_dir, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"generated_{timestamp}"
    
    filepath = os.path.join(save_dir, f"{filename}.png")
    image.save(filepath)
    print(f"å›¾ç‰‡å·²ä¿å­˜åˆ°: {filepath}")
    return filepath


def load_image(image_path: str) -> Image.Image:
    """
    åŠ è½½å›¾ç‰‡
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
    
    Returns:
        PIL Imageå¯¹è±¡
    """
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
    
    image = Image.open(image_path).convert("RGB")
    return image


def save_video(frames: List[Image.Image], filename: str = None, subfolder: str = None, fps: int = 8) -> str:
    """
    ä¿å­˜è§†é¢‘å¸§åºåˆ—ä¸ºè§†é¢‘æ–‡ä»¶
    
    Args:
        frames: PIL Imageå¯¹è±¡åˆ—è¡¨
        filename: æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰
        subfolder: å­æ–‡ä»¶å¤¹åç§°
        fps: å¸§ç‡
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    try:
        import imageio
    except ImportError:
        raise ImportError("è¯·å®‰è£… imageio å’Œ imageio-ffmpeg: pip install imageio imageio-ffmpeg")
    
    from config.modules_config import OUTPUT_VIDEOS_DIR
    
    # åˆ›å»ºå­æ–‡ä»¶å¤¹
    if subfolder:
        save_dir = os.path.join(OUTPUT_VIDEOS_DIR, subfolder)
        os.makedirs(save_dir, exist_ok=True)
    else:
        save_dir = OUTPUT_VIDEOS_DIR
        os.makedirs(save_dir, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    if filename is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"generated_{timestamp}"
    
    filepath = os.path.join(save_dir, f"{filename}.mp4")

    print(f"frames data: {frames}")
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
    frame_arrays = []
    for frame in frames:
        # ç¡®ä¿æ˜¯PIL Imageå¯¹è±¡
        print(f"frame data: {frames}")
        if isinstance(frame, Image.Image):
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if frame.mode != 'RGB':
                frame = frame.convert('RGB')
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç¡®ä¿æ•°æ®ç±»å‹ä¸ºuint8ï¼ŒèŒƒå›´åœ¨0-255
            frame_array = np.array(frame)
        else:
            # å¦‚æœå·²ç»æ˜¯numpyæ•°ç»„
            frame_array = np.array(frame)
        
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        if frame_array.dtype != np.uint8:
            # å¦‚æœæ˜¯æµ®ç‚¹æ•°ç±»å‹ï¼Œéœ€è¦è½¬æ¢ä¸ºuint8
            if np.issubdtype(frame_array.dtype, np.floating):
                # æµ®ç‚¹æ•°ç±»å‹ï¼Œæ£€æŸ¥èŒƒå›´
                if frame_array.min() >= 0.0 and frame_array.max() <= 1.0 + 1e-5:  # å…è®¸å°çš„æµ®ç‚¹è¯¯å·®
                    # 0-1èŒƒå›´ï¼Œè½¬æ¢ä¸º0-255
                    frame_array = (np.clip(frame_array, 0, 1) * 255).astype(np.uint8)
                else:
                    # å…¶ä»–èŒƒå›´ï¼Œç›´æ¥è£å‰ªåˆ°0-255
                    frame_array = np.clip(frame_array, 0, 255).astype(np.uint8)
            else:
                # æ•´æ•°ç±»å‹ï¼Œç›´æ¥è½¬æ¢
                frame_array = np.clip(frame_array, 0, 255).astype(np.uint8)
        
        frame_arrays.append(frame_array)
    
    # ä¿å­˜ä¸ºè§†é¢‘ï¼Œä½¿ç”¨æ›´é«˜è´¨é‡çš„è®¾ç½®
    # qualityå‚æ•°ï¼šå¯¹äºH.264ï¼Œå€¼è¶Šå°è´¨é‡è¶Šé«˜ï¼ˆ0æœ€å¥½ï¼‰ï¼Œæ¨èä½¿ç”¨5-10
    # æ·»åŠ åƒç´ æ ¼å¼å‚æ•°ç¡®ä¿å…¼å®¹æ€§
    imageio.mimwrite(
        filepath, 
        frame_arrays, 
        fps=fps, 
        codec='libx264',
        quality=5,  # æé«˜è§†é¢‘è´¨é‡ï¼ˆ0-10ï¼Œå€¼è¶Šå°è´¨é‡è¶Šé«˜ï¼‰
        pixelformat='yuv420p',  # æ·»åŠ åƒç´ æ ¼å¼ï¼Œæé«˜å…¼å®¹æ€§
        macro_block_size=1  # é¿å…å°ºå¯¸é—®é¢˜
    )
    print(f"è§†é¢‘å·²ä¿å­˜åˆ°: {filepath}")
    return filepath


def load_video(video_path: str) -> List[Image.Image]:
    """
    åŠ è½½è§†é¢‘æ–‡ä»¶ï¼Œè¿”å›å¸§åˆ—è¡¨
    
    Args:
        video_path: è§†é¢‘è·¯å¾„
    
    Returns:
        PIL Imageå¯¹è±¡åˆ—è¡¨
    """
    try:
        import imageio
    except ImportError:
        raise ImportError("è¯·å®‰è£… imageio å’Œ imageio-ffmpeg: pip install imageio imageio-ffmpeg")
    
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
    
    # è¯»å–è§†é¢‘å¸§
    reader = imageio.get_reader(video_path)
    frames = []
    for frame in reader:
        frames.append(Image.fromarray(frame))
    
    reader.close()
    print(f"å·²åŠ è½½è§†é¢‘: {video_path}ï¼Œå…± {len(frames)} å¸§")
    return frames


def video_to_frames(video_path: str, output_dir: str = None, max_frames: int = None) -> List[Image.Image]:
    """
    å°†è§†é¢‘è½¬æ¢ä¸ºå¸§åºåˆ—
    
    Args:
        video_path: è§†é¢‘è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¿å­˜å¸§ï¼‰
        max_frames: æœ€å¤§å¸§æ•°ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        PIL Imageå¯¹è±¡åˆ—è¡¨
    """
    frames = load_video(video_path)
    
    if max_frames and len(frames) > max_frames:
        # å‡åŒ€é‡‡æ ·
        indices = np.linspace(0, len(frames) - 1, max_frames, dtype=int)
        frames = [frames[i] for i in indices]
    
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        for i, frame in enumerate(frames):
            frame.save(os.path.join(output_dir, f"frame_{i:04d}.png"))
    
    return frames


def frames_to_video(frames: List[Image.Image], output_path: str, fps: int = 8) -> str:
    """
    å°†å¸§åºåˆ—è½¬æ¢ä¸ºè§†é¢‘
    
    Args:
        frames: PIL Imageå¯¹è±¡åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        fps: å¸§ç‡
    
    Returns:
        è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    try:
        import imageio
    except ImportError:
        raise ImportError("è¯·å®‰è£… imageio å’Œ imageio-ffmpeg: pip install imageio imageio-ffmpeg")
    
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else ".", exist_ok=True)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
    frame_arrays = []
    for frame in frames:
        # ç¡®ä¿æ˜¯PIL Imageå¯¹è±¡
        if isinstance(frame, Image.Image):
            # è½¬æ¢ä¸ºRGBæ¨¡å¼
            if frame.mode != 'RGB':
                frame = frame.convert('RGB')
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            frame_array = np.array(frame)
        else:
            # å¦‚æœå·²ç»æ˜¯numpyæ•°ç»„
            frame_array = np.array(frame)
        
        # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        if frame_array.dtype != np.uint8:
            # å¦‚æœæ˜¯æµ®ç‚¹æ•°ç±»å‹ï¼Œéœ€è¦è½¬æ¢ä¸ºuint8
            if np.issubdtype(frame_array.dtype, np.floating):
                # æµ®ç‚¹æ•°ç±»å‹ï¼Œæ£€æŸ¥èŒƒå›´
                if frame_array.min() >= 0.0 and frame_array.max() <= 1.0 + 1e-5:  # å…è®¸å°çš„æµ®ç‚¹è¯¯å·®
                    # 0-1èŒƒå›´ï¼Œè½¬æ¢ä¸º0-255
                    frame_array = (np.clip(frame_array, 0, 1) * 255).astype(np.uint8)
                else:
                    # å…¶ä»–èŒƒå›´ï¼Œç›´æ¥è£å‰ªåˆ°0-255
                    frame_array = np.clip(frame_array, 0, 255).astype(np.uint8)
            else:
                # æ•´æ•°ç±»å‹ï¼Œç›´æ¥è½¬æ¢
                frame_array = np.clip(frame_array, 0, 255).astype(np.uint8)
        
        frame_arrays.append(frame_array)
    
    # ä¿å­˜ä¸ºè§†é¢‘ï¼Œä½¿ç”¨é«˜è´¨é‡è®¾ç½®
    imageio.mimwrite(
        output_path, 
        frame_arrays, 
        fps=fps, 
        codec='libx264', 
        quality=5,
        pixelformat='yuv420p',
        macro_block_size=1
    )
    print(f"è§†é¢‘å·²ä¿å­˜åˆ°: {output_path}")
    return output_path


def resize_image(image: Image.Image, size: Tuple[int, int], keep_aspect: bool = True) -> Image.Image:
    """
    è°ƒæ•´å›¾ç‰‡å¤§å°
    
    Args:
        image: PIL Imageå¯¹è±¡
        size: ç›®æ ‡å°ºå¯¸ (width, height)
        keep_aspect: æ˜¯å¦ä¿æŒå®½é«˜æ¯”
    
    Returns:
        è°ƒæ•´åçš„PIL Imageå¯¹è±¡
    """
    if keep_aspect:
        image.thumbnail(size, Image.Resampling.LANCZOS)
        # åˆ›å»ºæ–°å›¾ç‰‡ï¼Œå±…ä¸­æ”¾ç½®
        new_image = Image.new("RGB", size, (0, 0, 0))
        paste_x = (size[0] - image.size[0]) // 2
        paste_y = (size[1] - image.size[1]) // 2
        new_image.paste(image, (paste_x, paste_y))
        return new_image
    else:
        return image.resize(size, Image.Resampling.LANCZOS)


def set_seed(seed: int):
    """
    è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯å¤ç°
    
    Args:
        seed: éšæœºç§å­
    """
    import random
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    print(f"éšæœºç§å­å·²è®¾ç½®ä¸º: {seed}")


def get_device() -> str:
    """
    è·å–å¯ç”¨è®¾å¤‡ï¼ˆCPUæˆ–CUDAï¼‰
    
    Returns:
        è®¾å¤‡åç§°
    """
    if torch.cuda.is_available():
        device = "cuda"
        print(f"ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = "cpu"
        print("ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®ä½¿ç”¨GPUï¼‰")
    return device


def get_image_info(image_path: str) -> dict:
    """
    è·å–å›¾ç‰‡ä¿¡æ¯
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
    
    Returns:
        åŒ…å«å›¾ç‰‡ä¿¡æ¯çš„å­—å…¸
    """
    image = load_image(image_path)
    return {
        "path": image_path,
        "size": image.size,
        "width": image.size[0],
        "height": image.size[1],
        "mode": image.mode,
        "format": image.format
    }


def get_video_info(video_path: str) -> dict:
    """
    è·å–è§†é¢‘ä¿¡æ¯
    
    Args:
        video_path: è§†é¢‘è·¯å¾„
    
    Returns:
        åŒ…å«è§†é¢‘ä¿¡æ¯çš„å­—å…¸
    """
    try:
        import imageio
    except ImportError:
        raise ImportError("è¯·å®‰è£… imageio å’Œ imageio-ffmpeg: pip install imageio imageio-ffmpeg")
    
    reader = imageio.get_reader(video_path)
    meta = reader.get_meta_data()
    frames = len(list(reader))
    reader.close()
    
    return {
        "path": video_path,
        "fps": meta.get("fps", 0),
        "duration": meta.get("duration", 0),
        "size": meta.get("size", (0, 0)),
        "frames": frames
    }


def load_model_from_local_file(pipeline_class, model_path: str, **kwargs):
    """
    ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ¨¡å‹ï¼ˆæ”¯æŒ .safetensors æˆ– .ckpt æ–‡ä»¶ï¼‰
    
    Args:
        pipeline_class: Pipelineç±»ï¼ˆå¦‚ StableDiffusionPipelineï¼‰
        model_path: æœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.safetensors æˆ– .ckptï¼‰æˆ–æ¨¡å‹ç›®å½•è·¯å¾„
        **kwargs: ä¼ é€’ç»™from_pretrainedæˆ–from_single_fileçš„å…¶ä»–å‚æ•°
    
    Returns:
        åŠ è½½çš„pipelineå¯¹è±¡
    
    Raises:
        FileNotFoundError: å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨
        ValueError: å¦‚æœæ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ
    """
    import os
    
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    print(f"\næ­£åœ¨ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¸ªæ–‡ä»¶ï¼ˆ.safetensors æˆ– .ckptï¼‰
    if os.path.isfile(model_path):
        file_ext = os.path.splitext(model_path)[1].lower()
        
        if file_ext in ['.safetensors', '.ckpt']:
            # ä½¿ç”¨ from_single_file æ–¹æ³•ï¼ˆdiffusers 0.21.0+ æ”¯æŒï¼‰
            try:
                print(f"æ£€æµ‹åˆ° {file_ext} æ ¼å¼ï¼Œä½¿ç”¨ from_single_file åŠ è½½...")
                pipe = pipeline_class.from_single_file(model_path, **kwargs)
                print("âœ… ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ¨¡å‹æˆåŠŸï¼")
                return pipe
            except AttributeError:
                # å¦‚æœ diffusers ç‰ˆæœ¬ä¸æ”¯æŒ from_single_fileï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                print("âš ï¸  å½“å‰ diffusers ç‰ˆæœ¬ä¸æ”¯æŒ from_single_fileï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")
                raise ValueError(
                    f"å½“å‰ diffusers ç‰ˆæœ¬ä¸æ”¯æŒä» {file_ext} æ–‡ä»¶åŠ è½½ã€‚"
                    f"è¯·å‡çº§ diffusers åˆ° 0.21.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œæˆ–ä½¿ç”¨æ¨¡å‹ç›®å½•æ ¼å¼ã€‚"
                )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}ã€‚æ”¯æŒæ ¼å¼: .safetensors, .ckpt")
    
    # å¦‚æœæ˜¯ç›®å½•ï¼Œä½¿ç”¨ from_pretrained
    elif os.path.isdir(model_path):
        print("æ£€æµ‹åˆ°æ¨¡å‹ç›®å½•ï¼Œä½¿ç”¨ from_pretrained åŠ è½½...")
        try:
            pipe = pipeline_class.from_pretrained(model_path, **kwargs)
            print("âœ… ä»æœ¬åœ°ç›®å½•åŠ è½½æ¨¡å‹æˆåŠŸï¼")
            return pipe
        except Exception as e:
            raise OSError(f"ä»æœ¬åœ°ç›®å½•åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
    
    else:
        raise ValueError(f"æ— æ•ˆçš„æ¨¡å‹è·¯å¾„: {model_path}")


def load_model_with_fallback(pipeline_class, model_name: str, **kwargs):
    """
    åŠ è½½æ¨¡å‹ï¼Œå¸¦é”™è¯¯å¤„ç†å’Œç¦»çº¿æ¨¡å¼æ”¯æŒ
    
    Args:
        pipeline_class: Pipelineç±»ï¼ˆå¦‚ StableDiffusionPipelineï¼‰
        model_name: æ¨¡å‹åç§°ï¼ˆHuggingFace IDï¼‰æˆ–æœ¬åœ°è·¯å¾„
        **kwargs: ä¼ é€’ç»™from_pretrainedçš„å…¶ä»–å‚æ•°
    
    Returns:
        åŠ è½½çš„pipelineå¯¹è±¡
    
    Raises:
        OSError: å¦‚æœæ¨¡å‹æ— æ³•åŠ è½½ä¸”æ²¡æœ‰æœ¬åœ°ç¼“å­˜
    """
    import os
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
    if os.path.exists(model_name):
        return load_model_from_local_file(pipeline_class, model_name, **kwargs)
    
    print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
    print("ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç¦»çº¿æ¨¡å¼
    offline_mode = os.getenv("HF_HUB_OFFLINE", "0") == "1"
    local_files_only = os.getenv("HF_HUB_LOCAL_FILES_ONLY", "0") == "1"
    
    if offline_mode or local_files_only:
        print("âš ï¸  ç¦»çº¿æ¨¡å¼ï¼šä»…ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹")
        kwargs["local_files_only"] = True
    
    try:
        # å°è¯•åŠ è½½æ¨¡å‹
        try:
            pipe = pipeline_class.from_pretrained(model_name, **kwargs)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return pipe
        except (OSError, Exception) as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œç›¸å…³é”™è¯¯
            error_str = str(e).lower()
            is_network_error = any(keyword in error_str for keyword in [
                'timeout', 'connection', 'connect', 'network', 
                'max retries', 'connection pool', 'huggingface.co'
            ])
            
            if not is_network_error:
                # éç½‘ç»œé”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                raise
            
            # ç½‘ç»œé”™è¯¯ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜
            print("\nâš ï¸  ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹...")
            print(f"   é”™è¯¯ä¿¡æ¯: {str(e)[:100]}...")
            
            # æ£€æŸ¥æœ¬åœ°ç¼“å­˜
            from huggingface_hub import HfFolder
            cache_dir = HfFolder.get_cache_dir()
            model_cache_path = os.path.join(cache_dir, "models--" + model_name.replace("/", "--"))
            
            if os.path.exists(model_cache_path):
                print(f"   æ‰¾åˆ°æœ¬åœ°ç¼“å­˜: {model_cache_path}")
                try:
                    kwargs["local_files_only"] = True
                    pipe = pipeline_class.from_pretrained(model_name, **kwargs)
                    print("âœ… ä»æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹æˆåŠŸï¼")
                    return pipe
                except Exception as cache_error:
                    print(f"   âŒ æœ¬åœ°ç¼“å­˜åŠ è½½å¤±è´¥: {cache_error}")
            
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            print("\n" + "="*60)
            print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            print("="*60)
            print("\nå¯èƒ½çš„åŸå› ï¼š")
            print("1. ç½‘ç»œè¿æ¥é—®é¢˜ï¼ˆæ— æ³•è¿æ¥åˆ° huggingface.coï¼‰")
            print("2. æ¨¡å‹æœªä¸‹è½½ä¸”æœ¬åœ°æ— ç¼“å­˜")
            print("\nè§£å†³æ–¹æ¡ˆï¼š")
            print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¡®ä¿å¯ä»¥è®¿é—® huggingface.co")
            print("2. ä½¿ç”¨ VPN æˆ–ä»£ç†ï¼ˆå¦‚æœåœ¨å—é™ç½‘ç»œç¯å¢ƒä¸­ï¼‰")
            print("3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç¼“å­˜ç›®å½•")
            print(f"   ç¼“å­˜ç›®å½•: {cache_dir}")
            print("4. è®¾ç½®ç¯å¢ƒå˜é‡å¯ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆå¦‚æœå·²æœ‰æœ¬åœ°ç¼“å­˜ï¼‰:")
            print("   set HF_HUB_LOCAL_FILES_ONLY=1")
            print("5. ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .safetensors å’Œ .ckpt æ ¼å¼ï¼‰")
            print("="*60)
            raise OSError(
                f"æ— æ³•åŠ è½½æ¨¡å‹ '{model_name}': ç½‘ç»œè¿æ¥å¤±è´¥ä¸”æœ¬åœ°æ— ç¼“å­˜ã€‚"
                f"è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ã€‚"
            ) from e
            
    except Exception as e:
        # å…¶ä»–é”™è¯¯ï¼ˆéç½‘ç»œé”™è¯¯ï¼‰
        if "ç½‘ç»œ" not in str(e) and "connection" not in str(e).lower():
            print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        raise


def load_transformers_model_with_fallback(
    processor_class,
    model_class,
    model_name: str,
    local_model_path: str = None,
    **kwargs
):
    """
    åŠ è½½ Transformers æ¨¡å‹ï¼ˆå¦‚ ViTï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
    
    Args:
        processor_class: å¤„ç†å™¨ç±»ï¼ˆå¦‚ AutoImageProcessorï¼‰
        model_class: æ¨¡å‹ç±»ï¼ˆå¦‚ AutoModelForImageClassificationï¼‰
        model_name: åœ¨çº¿æ¨¡å‹åç§°ï¼ˆHuggingFace IDï¼‰
        local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
                         - å¦‚æœä¸º Noneï¼Œåˆ™ä¸ä½¿ç”¨æœ¬åœ°æ¨¡å‹
                         - å¦‚æœä¸º "" æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™ç¦ç”¨æœ¬åœ°æ¨¡å‹
                         - å¦‚æœæŒ‡å®šè·¯å¾„ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
        **kwargs: ä¼ é€’ç»™ from_pretrained çš„å…¶ä»–å‚æ•°
    
    Returns:
        (processor, model) å…ƒç»„
    """
    import os
    
    processor = None
    model = None
    loaded_from_local = False
    
    # ç¡®å®šæœ¬åœ°æ¨¡å‹è·¯å¾„
    effective_local_path = local_model_path if local_model_path else None
    
    # ä¼˜å…ˆå°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹
    if effective_local_path and os.path.exists(effective_local_path):
        print(f"\nâœ… æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹è·¯å¾„: {effective_local_path}")
        print("   ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¦»çº¿æ¨¡å‹...")
        try:
            processor = processor_class.from_pretrained(effective_local_path, **kwargs)
            model = model_class.from_pretrained(effective_local_path, **kwargs)
            print("âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            loaded_from_local = True
        except Exception as e:
            print(f"âš ï¸  æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"   å›é€€åˆ°åœ¨çº¿æ¨¡å‹: {model_name}")
    elif effective_local_path:
        print(f"\nâš ï¸  æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {effective_local_path}")
        print(f"   ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
    else:
        print(f"\nğŸ“¡ ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
    
    # å¦‚æœæœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æœªé…ç½®ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å‹
    if not loaded_from_local:
        print("ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç¦»çº¿æ¨¡å¼
        offline_mode = os.getenv("HF_HUB_OFFLINE", "0") == "1"
        local_files_only = os.getenv("HF_HUB_LOCAL_FILES_ONLY", "0") == "1"
        
        if offline_mode or local_files_only:
            print("âš ï¸  ç¦»çº¿æ¨¡å¼ï¼šä»…ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹")
            kwargs["local_files_only"] = True
        
        try:
            processor = processor_class.from_pretrained(model_name, **kwargs)
            model = model_class.from_pretrained(model_name, **kwargs)
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            error_str = str(e).lower()
            is_network_error = any(keyword in error_str for keyword in [
                'timeout', 'connection', 'connect', 'network', 
                'max retries', 'connection pool', 'huggingface.co'
            ])
            
            if is_network_error:
                # å°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜
                print("\nâš ï¸  ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„æ¨¡å‹...")
                try:
                    kwargs["local_files_only"] = True
                    processor = processor_class.from_pretrained(model_name, **kwargs)
                    model = model_class.from_pretrained(model_name, **kwargs)
                    print("âœ… ä»æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹æˆåŠŸï¼")
                except Exception as cache_error:
                    print(f"âŒ æœ¬åœ°ç¼“å­˜åŠ è½½å¤±è´¥: {cache_error}")
                    raise OSError(
                        f"æ— æ³•åŠ è½½æ¨¡å‹ '{model_name}': ç½‘ç»œè¿æ¥å¤±è´¥ä¸”æœ¬åœ°æ— ç¼“å­˜ã€‚"
                        f"è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é…ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚"
                    ) from e
            else:
                raise
    
    return processor, model


def load_yolo_model_with_fallback(
    model_name: str = "yolov8n.pt",
    local_model_path: str = None
):
    """
    åŠ è½½ YOLO æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
    
    Args:
        model_name: åœ¨çº¿æ¨¡å‹åç§°ï¼ˆé»˜è®¤ yolov8n.ptï¼‰
        local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
                         - å¦‚æœä¸º Noneï¼Œåˆ™ä¸ä½¿ç”¨æœ¬åœ°æ¨¡å‹
                         - å¦‚æœä¸º "" æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™ç¦ç”¨æœ¬åœ°æ¨¡å‹
                         - å¦‚æœæŒ‡å®šè·¯å¾„ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
    
    Returns:
        YOLO æ¨¡å‹å¯¹è±¡
    """
    import os
    
    try:
        from ultralytics import YOLO
    except ImportError:
        raise ImportError("è¯·å®‰è£… ultralytics: pip install ultralytics")
    
    model = None
    effective_local_path = local_model_path if local_model_path else None
    
    # ä¼˜å…ˆå°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹
    if effective_local_path and os.path.exists(effective_local_path):
        print(f"\nâœ… æ£€æµ‹åˆ°æœ¬åœ°YOLOæ¨¡å‹è·¯å¾„: {effective_local_path}")
        print("   ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¦»çº¿æ¨¡å‹...")
        try:
            model = YOLO(effective_local_path)
            print("âœ… æœ¬åœ°YOLOæ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return model
        except Exception as e:
            print(f"âš ï¸  æœ¬åœ°YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"   å›é€€åˆ°åœ¨çº¿æ¨¡å‹: {model_name}")
    elif effective_local_path:
        print(f"\nâš ï¸  æœ¬åœ°YOLOæ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {effective_local_path}")
        print(f"   ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
    else:
        print(f"\nğŸ“¡ ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
    
    # ä½¿ç”¨åœ¨çº¿æ¨¡å‹
    print("ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
    try:
        model = YOLO(model_name)
        print("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸï¼")
        return model
    except Exception as e:
        print(f"\nâŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\næç¤ºï¼š")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. é…ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„ä»¥é¿å…ç½‘ç»œä¸‹è½½")
        raise


def load_diffusion_pipeline_with_fallback(
    pipeline_class,
    model_name: str,
    local_model_path: str = None,
    **kwargs
):
    """
    åŠ è½½ Diffusers Pipelineï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
    
    Args:
        pipeline_class: Pipelineç±»ï¼ˆå¦‚ StableDiffusionImg2ImgPipelineï¼‰
        model_name: åœ¨çº¿æ¨¡å‹åç§°ï¼ˆHuggingFace IDï¼‰
        local_model_path: æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆå¯é€‰ï¼‰
                         - å¦‚æœä¸º Noneï¼Œåˆ™ä¸ä½¿ç”¨æœ¬åœ°æ¨¡å‹
                         - å¦‚æœä¸º "" æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™ç¦ç”¨æœ¬åœ°æ¨¡å‹
                         - å¦‚æœæŒ‡å®šè·¯å¾„ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
        **kwargs: ä¼ é€’ç»™ from_pretrained çš„å…¶ä»–å‚æ•°
    
    Returns:
        åŠ è½½çš„ pipeline å¯¹è±¡
    """
    import os
    
    pipe = None
    loaded_from_local = False
    effective_local_path = local_model_path if local_model_path else None
    
    # ä¼˜å…ˆå°è¯•åŠ è½½æœ¬åœ°æ¨¡å‹
    if effective_local_path and os.path.exists(effective_local_path):
        print(f"\nâœ… æ£€æµ‹åˆ°æœ¬åœ°æ¨¡å‹è·¯å¾„: {effective_local_path}")
        print("   ä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¦»çº¿æ¨¡å‹...")
        try:
            pipe = load_model_from_local_file(pipeline_class, effective_local_path, **kwargs)
            print("âœ… æœ¬åœ°æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            loaded_from_local = True
        except Exception as e:
            print(f"âš ï¸  æœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"   å›é€€åˆ°åœ¨çº¿æ¨¡å‹: {model_name}")
    elif effective_local_path:
        print(f"\nâš ï¸  æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {effective_local_path}")
        print(f"   ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
    else:
        print(f"\nğŸ“¡ ä½¿ç”¨åœ¨çº¿æ¨¡å‹: {model_name}")
        print("   æ³¨æ„ï¼šæ¨¡å‹å¯èƒ½è¾ƒå¤§ï¼Œä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
    
    # å¦‚æœæœ¬åœ°æ¨¡å‹åŠ è½½å¤±è´¥æˆ–æœªé…ç½®ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å‹
    if not loaded_from_local:
        pipe = load_model_with_fallback(pipeline_class, model_name, **kwargs)
    
    return pipe